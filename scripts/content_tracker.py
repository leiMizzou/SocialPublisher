#!/usr/bin/env python3
"""
å†…å®¹è¿½è¸ªå’Œæ ¸æŸ¥ç³»ç»Ÿ
ç”¨äºè®°å½•ç¤¾äº¤åª’ä½“è¿è¥å…¨æµç¨‹çš„å†…å®¹ï¼Œå¹¶åœ¨å‘å¸ƒåè¿›è¡ŒéªŒè¯
"""

import json
import os
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional

# é…ç½®ç›®å½•
CONFIG_DIR = Path(__file__).parent.parent / ".social_publisher"
SESSIONS_DIR = CONFIG_DIR / "sessions"


def ensure_dirs():
    """ç¡®ä¿ç›®å½•å­˜åœ¨"""
    SESSIONS_DIR.mkdir(parents=True, exist_ok=True)


class ContentTracker:
    """å†…å®¹è¿½è¸ªå™¨"""

    def __init__(self, topic: str):
        ensure_dirs()
        self.topic = topic
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.session_file = SESSIONS_DIR / f"session_{self.session_id}.json"

        self.data = {
            "session_id": self.session_id,
            "topic": topic,
            "created_at": datetime.now().isoformat(),
            "status": "initialized",

            # Phase 1: æœç´¢ç»“æœ
            "search": {
                "query": "",
                "time_range": "",
                "total_found": 0,
                "posts": []  # æ‰€æœ‰æ‰¾åˆ°çš„å¸–å­
            },

            # Phase 2: é€‰å®šäº’åŠ¨çš„å¸–å­
            "engagement": {
                "selected_posts": [],  # é€‰å®šè¦äº’åŠ¨çš„å¸–å­ID
                "liked": [],           # å·²ç‚¹èµçš„å¸–å­ID
                "replied": [],         # å·²å›å¤çš„å¸–å­ID
                "replies_content": {}  # å›å¤å†…å®¹ {post_id: reply_text}
            },

            # Phase 3: æç‚¼çš„å†…å®¹
            "distilled": {
                "trends": [],
                "key_points": [],
                "quotes": [],
                "summary": ""
            },

            # Phase 4: å„å¹³å°ç”Ÿæˆçš„å†…å®¹
            "generated_content": {
                "twitter": {
                    "thread": [],  # æ¯æ¡æ¨æ–‡
                    "total_tweets": 0
                },
                "xiaohongshu": {
                    "title": "",
                    "content": "",
                    "hashtags": []
                },
                "wechat": {
                    "title": "",
                    "content": "",
                    "summary": ""
                }
            },

            # Phase 5: å‘å¸ƒçŠ¶æ€
            "publish_status": {
                "twitter": {
                    "status": "pending",  # pending, published, failed, partial
                    "published_count": 0,
                    "expected_count": 0,
                    "urls": [],
                    "errors": []
                },
                "xiaohongshu": {
                    "status": "pending",
                    "url": "",
                    "errors": []
                },
                "wechat": {
                    "status": "pending",
                    "url": "",
                    "errors": []
                }
            },

            # Phase 6: æ ¸æŸ¥ç»“æœ
            "verification": {
                "verified_at": "",
                "twitter_verified": False,
                "xiaohongshu_verified": False,
                "wechat_verified": False,
                "issues": [],
                "notes": ""
            }
        }

        self._save()

    def _save(self):
        """ä¿å­˜ä¼šè¯æ•°æ®"""
        with open(self.session_file, "w", encoding="utf-8") as f:
            json.dump(self.data, f, ensure_ascii=False, indent=2)

    @classmethod
    def load(cls, session_id: str) -> "ContentTracker":
        """åŠ è½½å·²æœ‰ä¼šè¯"""
        session_file = SESSIONS_DIR / f"session_{session_id}.json"
        if not session_file.exists():
            raise FileNotFoundError(f"Session {session_id} not found")

        with open(session_file, "r", encoding="utf-8") as f:
            data = json.load(f)

        tracker = cls.__new__(cls)
        tracker.topic = data["topic"]
        tracker.session_id = session_id
        tracker.session_file = session_file
        tracker.data = data
        return tracker

    @classmethod
    def get_latest_session(cls) -> Optional["ContentTracker"]:
        """è·å–æœ€æ–°çš„ä¼šè¯"""
        ensure_dirs()
        sessions = list(SESSIONS_DIR.glob("session_*.json"))
        if not sessions:
            return None
        latest = max(sessions, key=lambda p: p.stat().st_mtime)
        session_id = latest.stem.replace("session_", "")
        return cls.load(session_id)

    # ========== Phase 1: æœç´¢ ==========

    def record_search(self, query: str, time_range: str, posts: List[Dict]):
        """è®°å½•æœç´¢ç»“æœ"""
        self.data["search"]["query"] = query
        self.data["search"]["time_range"] = time_range
        self.data["search"]["total_found"] = len(posts)
        self.data["search"]["posts"] = posts
        self.data["status"] = "searched"
        self._save()
        print(f"ğŸ“ å·²è®°å½• {len(posts)} æ¡æœç´¢ç»“æœ")

    # ========== Phase 2: äº’åŠ¨ ==========

    def record_selected_for_engagement(self, post_ids: List[str]):
        """è®°å½•é€‰å®šè¦äº’åŠ¨çš„å¸–å­"""
        self.data["engagement"]["selected_posts"] = post_ids
        self._save()
        print(f"ğŸ“ å·²è®°å½• {len(post_ids)} æ¡é€‰å®šäº’åŠ¨çš„å¸–å­")

    def record_like(self, post_id: str):
        """è®°å½•ç‚¹èµ"""
        if post_id not in self.data["engagement"]["liked"]:
            self.data["engagement"]["liked"].append(post_id)
            self._save()

    def record_reply(self, post_id: str, reply_text: str):
        """è®°å½•å›å¤"""
        if post_id not in self.data["engagement"]["replied"]:
            self.data["engagement"]["replied"].append(post_id)
        self.data["engagement"]["replies_content"][post_id] = reply_text
        self._save()

    # ========== Phase 3: æç‚¼ ==========

    def record_distilled_content(self, trends: List[str], key_points: List[str],
                                  quotes: List[Dict], summary: str):
        """è®°å½•æç‚¼çš„å†…å®¹"""
        self.data["distilled"] = {
            "trends": trends,
            "key_points": key_points,
            "quotes": quotes,
            "summary": summary
        }
        self.data["status"] = "distilled"
        self._save()
        print(f"ğŸ“ å·²è®°å½•æç‚¼å†…å®¹: {len(trends)} ä¸ªè¶‹åŠ¿, {len(key_points)} ä¸ªè¦ç‚¹")

    # ========== Phase 4: ç”Ÿæˆå†…å®¹ ==========

    def record_twitter_content(self, thread: List[str]):
        """è®°å½• Twitter Thread å†…å®¹"""
        self.data["generated_content"]["twitter"]["thread"] = thread
        self.data["generated_content"]["twitter"]["total_tweets"] = len(thread)
        self.data["publish_status"]["twitter"]["expected_count"] = len(thread)
        self._save()
        print(f"ğŸ“ å·²è®°å½• Twitter Thread: {len(thread)} æ¡æ¨æ–‡")

    def record_xiaohongshu_content(self, title: str, content: str, hashtags: List[str] = None):
        """è®°å½•å°çº¢ä¹¦å†…å®¹"""
        self.data["generated_content"]["xiaohongshu"] = {
            "title": title,
            "content": content,
            "hashtags": hashtags or []
        }
        self._save()
        print(f"ğŸ“ å·²è®°å½•å°çº¢ä¹¦å†…å®¹: {title}")

    def record_wechat_content(self, title: str, content: str, summary: str = ""):
        """è®°å½•å¾®ä¿¡å…¬ä¼—å·å†…å®¹"""
        self.data["generated_content"]["wechat"] = {
            "title": title,
            "content": content,
            "summary": summary
        }
        self._save()
        print(f"ğŸ“ å·²è®°å½•å¾®ä¿¡å…¬ä¼—å·å†…å®¹: {title}")

    # ========== Phase 5: å‘å¸ƒçŠ¶æ€ ==========

    def record_twitter_publish(self, published_count: int, urls: List[str] = None,
                                status: str = "published", error: str = None):
        """è®°å½• Twitter å‘å¸ƒçŠ¶æ€"""
        self.data["publish_status"]["twitter"]["published_count"] = published_count
        self.data["publish_status"]["twitter"]["status"] = status
        if urls:
            self.data["publish_status"]["twitter"]["urls"] = urls
        if error:
            self.data["publish_status"]["twitter"]["errors"].append(error)
        self._save()

    def record_xiaohongshu_publish(self, url: str = "", status: str = "published",
                                    error: str = None):
        """è®°å½•å°çº¢ä¹¦å‘å¸ƒçŠ¶æ€"""
        self.data["publish_status"]["xiaohongshu"]["status"] = status
        self.data["publish_status"]["xiaohongshu"]["url"] = url
        if error:
            self.data["publish_status"]["xiaohongshu"]["errors"].append(error)
        self._save()

    def record_wechat_publish(self, url: str = "", status: str = "published",
                               error: str = None):
        """è®°å½•å¾®ä¿¡å‘å¸ƒçŠ¶æ€"""
        self.data["publish_status"]["wechat"]["status"] = status
        self.data["publish_status"]["wechat"]["url"] = url
        if error:
            self.data["publish_status"]["wechat"]["errors"].append(error)
        self._save()

    # ========== Phase 6: æ ¸æŸ¥ ==========

    def verify(self) -> Dict:
        """æ‰§è¡Œæ ¸æŸ¥å¹¶è¿”å›ç»“æœ"""
        issues = []

        # æ£€æŸ¥ Twitter
        twitter_status = self.data["publish_status"]["twitter"]
        twitter_content = self.data["generated_content"]["twitter"]

        if twitter_status["expected_count"] > 0:
            if twitter_status["published_count"] < twitter_status["expected_count"]:
                issues.append({
                    "platform": "twitter",
                    "type": "incomplete",
                    "expected": twitter_status["expected_count"],
                    "actual": twitter_status["published_count"],
                    "message": f"Twitter Thread æœªå‘å®Œ: é¢„æœŸ {twitter_status['expected_count']} æ¡, å®é™… {twitter_status['published_count']} æ¡"
                })
            elif twitter_status["status"] != "published":
                issues.append({
                    "platform": "twitter",
                    "type": "status",
                    "message": f"Twitter çŠ¶æ€å¼‚å¸¸: {twitter_status['status']}"
                })

        # æ£€æŸ¥å°çº¢ä¹¦
        xhs_status = self.data["publish_status"]["xiaohongshu"]
        if self.data["generated_content"]["xiaohongshu"]["title"]:
            if xhs_status["status"] != "published":
                issues.append({
                    "platform": "xiaohongshu",
                    "type": "status",
                    "message": f"å°çº¢ä¹¦çŠ¶æ€: {xhs_status['status']}"
                })

        # æ£€æŸ¥å¾®ä¿¡
        wechat_status = self.data["publish_status"]["wechat"]
        if self.data["generated_content"]["wechat"]["title"]:
            if wechat_status["status"] not in ["published", "draft"]:
                issues.append({
                    "platform": "wechat",
                    "type": "status",
                    "message": f"å¾®ä¿¡å…¬ä¼—å·çŠ¶æ€: {wechat_status['status']}"
                })

        # æ›´æ–°æ ¸æŸ¥ç»“æœ
        self.data["verification"] = {
            "verified_at": datetime.now().isoformat(),
            "twitter_verified": len([i for i in issues if i["platform"] == "twitter"]) == 0,
            "xiaohongshu_verified": len([i for i in issues if i["platform"] == "xiaohongshu"]) == 0,
            "wechat_verified": len([i for i in issues if i["platform"] == "wechat"]) == 0,
            "issues": issues,
            "notes": ""
        }
        self.data["status"] = "verified"
        self._save()

        return self.data["verification"]

    def get_report(self) -> str:
        """ç”Ÿæˆæ ¸æŸ¥æŠ¥å‘Š"""
        report = []
        report.append("=" * 60)
        report.append(f"ğŸ“‹ å†…å®¹è¿½è¸ªæŠ¥å‘Š")
        report.append(f"   ä¼šè¯ID: {self.session_id}")
        report.append(f"   ä¸»é¢˜: {self.topic}")
        report.append(f"   æ—¶é—´: {self.data['created_at']}")
        report.append("=" * 60)

        # æœç´¢é˜¶æ®µ
        search = self.data["search"]
        report.append(f"\nğŸ” æœç´¢é˜¶æ®µ:")
        report.append(f"   æŸ¥è¯¢: {search['query']}")
        report.append(f"   æ—¶é—´èŒƒå›´: {search['time_range']}")
        report.append(f"   æ‰¾åˆ°å¸–å­: {search['total_found']} æ¡")

        # äº’åŠ¨é˜¶æ®µ
        engagement = self.data["engagement"]
        report.append(f"\nğŸ’¬ äº’åŠ¨é˜¶æ®µ:")
        report.append(f"   é€‰å®šäº’åŠ¨: {len(engagement['selected_posts'])} æ¡")
        report.append(f"   å·²ç‚¹èµ: {len(engagement['liked'])} æ¡")
        report.append(f"   å·²å›å¤: {len(engagement['replied'])} æ¡")

        # ç”Ÿæˆå†…å®¹
        generated = self.data["generated_content"]
        report.append(f"\nğŸ“ ç”Ÿæˆå†…å®¹:")
        report.append(f"   Twitter Thread: {generated['twitter']['total_tweets']} æ¡æ¨æ–‡")
        report.append(f"   å°çº¢ä¹¦: {generated['xiaohongshu']['title'] or '(æ— )'}")
        report.append(f"   å¾®ä¿¡å…¬ä¼—å·: {generated['wechat']['title'] or '(æ— )'}")

        # å‘å¸ƒçŠ¶æ€
        publish = self.data["publish_status"]
        report.append(f"\nğŸ“¤ å‘å¸ƒçŠ¶æ€:")

        # Twitter
        tw = publish["twitter"]
        tw_emoji = "âœ…" if tw["status"] == "published" and tw["published_count"] == tw["expected_count"] else "âš ï¸"
        report.append(f"   {tw_emoji} Twitter: {tw['status']} ({tw['published_count']}/{tw['expected_count']} æ¡)")

        # å°çº¢ä¹¦
        xhs = publish["xiaohongshu"]
        xhs_emoji = "âœ…" if xhs["status"] == "published" else "âš ï¸"
        report.append(f"   {xhs_emoji} å°çº¢ä¹¦: {xhs['status']}")

        # å¾®ä¿¡
        wc = publish["wechat"]
        wc_emoji = "âœ…" if wc["status"] in ["published", "draft"] else "âš ï¸"
        report.append(f"   {wc_emoji} å¾®ä¿¡å…¬ä¼—å·: {wc['status']}")

        # æ ¸æŸ¥ç»“æœ
        if self.data["verification"]["verified_at"]:
            verification = self.data["verification"]
            report.append(f"\nğŸ” æ ¸æŸ¥ç»“æœ:")

            if verification["issues"]:
                for issue in verification["issues"]:
                    report.append(f"   âš ï¸ {issue['message']}")
            else:
                report.append("   âœ… æ‰€æœ‰å†…å®¹å‘å¸ƒå®Œæ•´")

        report.append("\n" + "=" * 60)

        return "\n".join(report)

    def get_unpublished_twitter_content(self) -> List[str]:
        """è·å–æœªå‘å¸ƒçš„ Twitter å†…å®¹"""
        twitter = self.data["generated_content"]["twitter"]
        publish = self.data["publish_status"]["twitter"]

        published_count = publish["published_count"]
        all_tweets = twitter["thread"]

        if published_count < len(all_tweets):
            return all_tweets[published_count:]
        return []


# ========== CLI ==========

def main():
    import argparse

    parser = argparse.ArgumentParser(description="å†…å®¹è¿½è¸ªå’Œæ ¸æŸ¥ç³»ç»Ÿ")
    subparsers = parser.add_subparsers(dest="command")

    # init å‘½ä»¤ - åˆå§‹åŒ–æ–°ä¼šè¯
    init_parser = subparsers.add_parser("init", help="åˆå§‹åŒ–æ–°ä¼šè¯")
    init_parser.add_argument("--topic", "-t", required=True, help="ä¸»é¢˜å…³é”®è¯")

    # search å‘½ä»¤ - è®°å½•æœç´¢ç»“æœ
    search_parser = subparsers.add_parser("search", help="è®°å½•æœç´¢ç»“æœ")
    search_parser.add_argument("--session", "-s", help="ä¼šè¯IDï¼Œé»˜è®¤æœ€æ–°")
    search_parser.add_argument("--query", "-q", required=True, help="æœç´¢æŸ¥è¯¢è¯")
    search_parser.add_argument("--time-range", "-r", default="24h", help="æ—¶é—´èŒƒå›´")
    search_parser.add_argument("--posts", "-p", help="å¸–å­JSONæ•°ç»„ï¼ˆæˆ–ä»stdinè¯»å–ï¼‰")

    # engage å‘½ä»¤ - è®°å½•äº’åŠ¨
    engage_parser = subparsers.add_parser("engage", help="è®°å½•äº’åŠ¨")
    engage_parser.add_argument("--session", "-s", help="ä¼šè¯IDï¼Œé»˜è®¤æœ€æ–°")
    engage_parser.add_argument("--action", "-a", choices=["select", "like", "reply"], required=True)
    engage_parser.add_argument("--post-id", "-p", help="å¸–å­ID")
    engage_parser.add_argument("--post-ids", help="å¤šä¸ªå¸–å­IDï¼Œé€—å·åˆ†éš”")
    engage_parser.add_argument("--reply-text", help="å›å¤å†…å®¹")

    # distill å‘½ä»¤ - è®°å½•æç‚¼å†…å®¹
    distill_parser = subparsers.add_parser("distill", help="è®°å½•æç‚¼å†…å®¹")
    distill_parser.add_argument("--session", "-s", help="ä¼šè¯IDï¼Œé»˜è®¤æœ€æ–°")
    distill_parser.add_argument("--trends", help="è¶‹åŠ¿JSONæ•°ç»„")
    distill_parser.add_argument("--points", help="è¦ç‚¹JSONæ•°ç»„")
    distill_parser.add_argument("--quotes", help="å¼•ç”¨JSONæ•°ç»„")
    distill_parser.add_argument("--summary", help="æ€»ç»“")

    # generate å‘½ä»¤ - è®°å½•ç”Ÿæˆçš„å†…å®¹
    generate_parser = subparsers.add_parser("generate", help="è®°å½•ç”Ÿæˆçš„å†…å®¹")
    generate_parser.add_argument("--session", "-s", help="ä¼šè¯IDï¼Œé»˜è®¤æœ€æ–°")
    generate_parser.add_argument("--platform", "-p", choices=["twitter", "xiaohongshu", "wechat"], required=True)
    generate_parser.add_argument("--title", "-t", help="æ ‡é¢˜")
    generate_parser.add_argument("--content", "-c", help="å†…å®¹")
    generate_parser.add_argument("--thread", help="Twitter Thread JSONæ•°ç»„")
    generate_parser.add_argument("--hashtags", help="è¯é¢˜æ ‡ç­¾ï¼Œé€—å·åˆ†éš”")

    # publish å‘½ä»¤ - è®°å½•å‘å¸ƒçŠ¶æ€
    publish_parser = subparsers.add_parser("publish", help="è®°å½•å‘å¸ƒçŠ¶æ€")
    publish_parser.add_argument("--session", "-s", help="ä¼šè¯IDï¼Œé»˜è®¤æœ€æ–°")
    publish_parser.add_argument("--platform", "-p", choices=["twitter", "xiaohongshu", "wechat"], required=True)
    publish_parser.add_argument("--status", choices=["pending", "published", "partial", "failed", "draft"], default="published")
    publish_parser.add_argument("--url", "-u", help="å‘å¸ƒURL")
    publish_parser.add_argument("--count", "-n", type=int, help="å·²å‘å¸ƒæ•°é‡ï¼ˆTwitterç”¨ï¼‰")
    publish_parser.add_argument("--error", "-e", help="é”™è¯¯ä¿¡æ¯")

    # list å‘½ä»¤
    list_parser = subparsers.add_parser("list", help="åˆ—å‡ºæ‰€æœ‰ä¼šè¯")

    # report å‘½ä»¤
    report_parser = subparsers.add_parser("report", help="æŸ¥çœ‹æ ¸æŸ¥æŠ¥å‘Š")
    report_parser.add_argument("--session", "-s", help="æŒ‡å®šä¼šè¯IDï¼Œé»˜è®¤æœ€æ–°")

    # verify å‘½ä»¤
    verify_parser = subparsers.add_parser("verify", help="æ‰§è¡Œæ ¸æŸ¥")
    verify_parser.add_argument("--session", "-s", help="æŒ‡å®šä¼šè¯IDï¼Œé»˜è®¤æœ€æ–°")

    # session-id å‘½ä»¤ - è·å–å½“å‰ä¼šè¯ID
    session_parser = subparsers.add_parser("session-id", help="è·å–æœ€æ–°ä¼šè¯ID")

    args = parser.parse_args()

    # ========== init ==========
    if args.command == "init":
        tracker = ContentTracker(args.topic)
        print(f"âœ… æ–°ä¼šè¯å·²åˆ›å»º: {tracker.session_id}")
        print(tracker.session_id)  # è¾“å‡ºIDä¾›è„šæœ¬æ•è·

    # ========== search ==========
    elif args.command == "search":
        tracker = ContentTracker.load(args.session) if args.session else ContentTracker.get_latest_session()
        if not tracker:
            print("âŒ æœªæ‰¾åˆ°ä¼šè¯ï¼Œè¯·å…ˆè¿è¡Œ init")
            return

        posts = []
        if args.posts:
            posts = json.loads(args.posts)
        else:
            # ä» stdin è¯»å–
            import sys
            if not sys.stdin.isatty():
                posts = json.load(sys.stdin)

        tracker.record_search(args.query, args.time_range, posts)

    # ========== engage ==========
    elif args.command == "engage":
        tracker = ContentTracker.load(args.session) if args.session else ContentTracker.get_latest_session()
        if not tracker:
            print("âŒ æœªæ‰¾åˆ°ä¼šè¯")
            return

        if args.action == "select":
            post_ids = args.post_ids.split(",") if args.post_ids else [args.post_id]
            tracker.record_selected_for_engagement(post_ids)
        elif args.action == "like":
            tracker.record_like(args.post_id)
            print(f"âœ… å·²è®°å½•ç‚¹èµ: {args.post_id}")
        elif args.action == "reply":
            tracker.record_reply(args.post_id, args.reply_text or "")
            print(f"âœ… å·²è®°å½•å›å¤: {args.post_id}")

    # ========== distill ==========
    elif args.command == "distill":
        tracker = ContentTracker.load(args.session) if args.session else ContentTracker.get_latest_session()
        if not tracker:
            print("âŒ æœªæ‰¾åˆ°ä¼šè¯")
            return

        trends = json.loads(args.trends) if args.trends else []
        points = json.loads(args.points) if args.points else []
        quotes = json.loads(args.quotes) if args.quotes else []
        summary = args.summary or ""

        tracker.record_distilled_content(trends, points, quotes, summary)

    # ========== generate ==========
    elif args.command == "generate":
        tracker = ContentTracker.load(args.session) if args.session else ContentTracker.get_latest_session()
        if not tracker:
            print("âŒ æœªæ‰¾åˆ°ä¼šè¯")
            return

        if args.platform == "twitter":
            thread = json.loads(args.thread) if args.thread else []
            tracker.record_twitter_content(thread)
        elif args.platform == "xiaohongshu":
            hashtags = args.hashtags.split(",") if args.hashtags else []
            tracker.record_xiaohongshu_content(args.title or "", args.content or "", hashtags)
        elif args.platform == "wechat":
            tracker.record_wechat_content(args.title or "", args.content or "", "")

    # ========== publish ==========
    elif args.command == "publish":
        tracker = ContentTracker.load(args.session) if args.session else ContentTracker.get_latest_session()
        if not tracker:
            print("âŒ æœªæ‰¾åˆ°ä¼šè¯")
            return

        if args.platform == "twitter":
            tracker.record_twitter_publish(
                published_count=args.count or 0,
                urls=[args.url] if args.url else [],
                status=args.status,
                error=args.error
            )
        elif args.platform == "xiaohongshu":
            tracker.record_xiaohongshu_publish(
                url=args.url or "",
                status=args.status,
                error=args.error
            )
        elif args.platform == "wechat":
            tracker.record_wechat_publish(
                url=args.url or "",
                status=args.status,
                error=args.error
            )
        print(f"âœ… å·²è®°å½• {args.platform} å‘å¸ƒçŠ¶æ€: {args.status}")

    # ========== list ==========
    elif args.command == "list":
        ensure_dirs()
        sessions = list(SESSIONS_DIR.glob("session_*.json"))
        if not sessions:
            print("æš‚æ— ä¼šè¯è®°å½•")
            return

        print("ğŸ“ ä¼šè¯åˆ—è¡¨:")
        for session_file in sorted(sessions, reverse=True)[:10]:
            with open(session_file, "r", encoding="utf-8") as f:
                data = json.load(f)
            print(f"   {data['session_id']} - {data['topic']} ({data['status']})")

    # ========== report ==========
    elif args.command == "report":
        tracker = ContentTracker.load(args.session) if args.session else ContentTracker.get_latest_session()
        if tracker:
            print(tracker.get_report())
        else:
            print("æœªæ‰¾åˆ°ä¼šè¯è®°å½•")

    # ========== verify ==========
    elif args.command == "verify":
        tracker = ContentTracker.load(args.session) if args.session else ContentTracker.get_latest_session()
        if tracker:
            result = tracker.verify()
            print(tracker.get_report())

            if result["issues"]:
                print("\nğŸ’¡ å»ºè®®æ“ä½œ:")
                for issue in result["issues"]:
                    if issue["type"] == "incomplete" and issue["platform"] == "twitter":
                        unpublished = tracker.get_unpublished_twitter_content()
                        if unpublished:
                            print(f"   éœ€è¦è¡¥å‘ {len(unpublished)} æ¡æ¨æ–‡:")
                            for i, tweet in enumerate(unpublished, 1):
                                print(f"   {i}. {tweet[:50]}...")
        else:
            print("æœªæ‰¾åˆ°ä¼šè¯è®°å½•")

    # ========== session-id ==========
    elif args.command == "session-id":
        tracker = ContentTracker.get_latest_session()
        if tracker:
            print(tracker.session_id)
        else:
            print("")

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
